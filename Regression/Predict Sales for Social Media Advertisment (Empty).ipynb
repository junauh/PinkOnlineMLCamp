{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Sales for Social Media Advertisment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![social_media](images/social-media.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda:\n",
    "* How do we load the advertisement dataset into the notebook?\n",
    "* How does the advertisement dataset looks like?\n",
    "* How do we describe a dataset using machine learning terminology?\n",
    "* How do we visualize data using seaborn?\n",
    "* What is the linear regression model?\n",
    "* How do we split, train and evaluate a model?\n",
    "* What is feature selection?\n",
    "* What is cross-validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the dataset\n",
    "### Start with reading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conventional way to import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CSV file using a relative path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __filepath_or_buffer__: The relative path to the file containing the data\n",
    "* __index_col__: The column to use as index in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main object types:\n",
    "\n",
    "* __DataFrame__: rows and columns\n",
    "* __Series__: single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the last 5 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of the DataFrame (rows, columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the data\n",
    "The dataset consist of the cost of advertisement on three social media platforms and the sales of a single product in a given market.\n",
    "\n",
    "### Machine learning terminology\n",
    "\n",
    "* Each row is an __observation__ (also known as: sample, example, instance, record)\n",
    "* Each column is a __feature__ (also known as: predictor, attribute, independent variable, input, regressor, covariate)\n",
    "* Each value we are predicting is the __response__ (also known as: target, outcome, label, dependent variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the name of the three features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first five rows of the features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Facebook:__ advertising dollars spent on Facebook for a single product in a given market (in thousands of dollars)\n",
    "* __Instagram:__ advertising dollars spent on Instagram\n",
    "* __Twitter:__ advertising dollars spent on Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the response?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the name of the response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first five rows of the response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Sales:__ sales of a single product in a given market (in thousands of items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the difference between the response of the iris and the sales advertisment dataset?\n",
    "\n",
    "The response of the iris dataset is categorical, while the response of the sales advertisment dataset is continous, which means this is a regression problem.\n",
    "\n",
    "* __Classification__ is supervised learning in which the response is categorical\n",
    "* __Regression__ is supervised learning in which the response is continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing data using seaborn\n",
    "__Seaborn:__ Python library for statistical data visualization built on top of Matplotlib\n",
    "\n",
    "* Anaconda users: run conda __install seaborn__ from the command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conventional way to import seaborn\n",
    "\n",
    "\n",
    "# allow plots to appear within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the relationship between the features and the response using scatterplots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "Why are we using linear regression?\n",
    "\n",
    "* widely used\n",
    "* runs fast\n",
    "* easy to use (not a lot of tuning required)\n",
    "* highly interpretable\n",
    "* basis for many other methods\n",
    "\n",
    "Note: unlikely to produce the best predictive accuracy (presumes a linear relationship between the features and response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "Simple linear regression is an approach for predicting a __quantitative response__ using a __single feature__ (or \"predictor\" or \"input variable\"). It takes the following form:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x$\n",
    "\n",
    "What does each term represent?\n",
    "\n",
    "* $y$ is the response\n",
    "* $x$ is the feature\n",
    "* $\\beta_0$ is the intercept\n",
    "* $\\beta_1$ is the coefficient for x\n",
    "\n",
    "Together, $\\beta_0$ and $\\beta_1$ are called the model coefficients. To create your model, you must \"learn\" the values of these coefficients. And once we've learned these coefficients, we can use the model to predict Sales!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating (\"Learning\") Model Coefficients\n",
    "\n",
    "Generally speaking, coefficients are estimated using the least squares criterion, which means we are finding the line (mathematically) which minimizes the sum of squared residuals (or \"sum of squared errors\"):\n",
    "\n",
    "![least_squares](images/estimating_coefficients.png)\n",
    "\n",
    "What elements are present in the diagram?\n",
    "\n",
    "* The black dots are the observed values of x and y.\n",
    "* The blue line is our least squares line.\n",
    "* The red lines are the residuals, which are the distances between the observed values and the least squares line.\n",
    "\n",
    "How do the model coefficients relate to the least squares line?\n",
    "\n",
    "* $\\beta_0$ is the __intercept__ (the value of $y$ when $x$=0)\n",
    "* $\\beta_1$ is the __slope__ (the change in $y$ divided by change in $x$)\n",
    "\n",
    "Here is a graphical depiction of those calculations:\n",
    "\n",
    "![slope_intercept](images/slope_intercept.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "Simple linear regression can easily be extended to include multiple features. This is called multiple linear regression:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n$\n",
    "\n",
    "Each $x$ represents a different feature, and each feature has its own coefficient. In this case:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1 \\times Facebook + \\beta_2 \\times Instagram + \\beta_3 \\times Twitter$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the input data (feature matrix \"X\" and response vector \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Python list of feature names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the list to select a subset of the original DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which datatype and size do we expect X to have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the type and shape of X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the response vector from the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 5 values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which datatype and size do we expect y to have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the type and shape of y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow the following procedure\n",
    "\n",
    "1. Split the dataset into two pieces: a __training set__ and a __testing set__.\n",
    "2. Train the model on the __training set__.\n",
    "3. Test the model on the __testing set__, and evaluate how well we did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we want to split the data into a training_set and a testing_set?\n",
    "\n",
    "* The goal is to estimate the model performance on out-of-sample (unseen) data\n",
    "* Training and testing on the same data will result in overly complex models that will overfit the data. \n",
    "\n",
    "![Overfitting](images/05_overfitting.png)\n",
    "\n",
    "*Image Credit: [Overfitting](http://commons.wikimedia.org/wiki/File:Overfitting.svg#/media/File:Overfitting.svg) by Chabacano. Licensed under GFDL via Wikimedia Commons.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Split the dataset into two pieces: a __training_set__ and a __testing_set__\n",
    "\n",
    "* The goal is to avoid overfitting and estimate how well a model performs on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __test_size__: the proportion of the dataset to include in the test set\n",
    "* __random_state__: controls the shuffling applied to the data before applying the split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Train/test split](images/05_train_test_split.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did this accomplish?\n",
    "\n",
    "* Model can be trained and tested on __different data__\n",
    "* Response values are known for the testing set, and thus __predictions can be evaluated__\n",
    "* __Testing accuracy__ is a better estimate than training accuracy of out-of-sample performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shapes of the new X objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shapes of the new y objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train the model with linear regression on the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 1:__ Import the class (model) you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2:__ \"Instantiate\" the \"estimator\"\n",
    "\n",
    "* \"Estimator\" is scikit-learn's term for model\n",
    "* \"Instantiate\" means \"make an instance of\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Name of the object does not matter\n",
    "* Linear regression does not require parameter tuning (compared to KNN)\n",
    "* All parameters not specified are set to their defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 3:__ Fit the model with the training data (aka \"model training\")\n",
    "\n",
    "* Model is learning the coefficients\n",
    "* Occurs in-place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intepreteing the model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the intercept and coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair the feature names with the coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = 2.91 + 0.0468 \\times Facebook + 0.179 \\times Instagram + 0.00259 \\times Twitter$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we interpret the __Facebook coefficient__ (0.0468)?\n",
    "\n",
    "* For a given amount of Instagram and Twitter ad spending, __a \"unit\" increase in Facebook ad spending__ is associated with a __0.0468 \"unit\" increase in Sales__.\n",
    "* Or more clearly: For a given amount of Instagram and Twitter ad spending, __an additional $1,000 spent on Facebook ads__ is associated with an __increase in sales of 46.8 items__.\n",
    "\n",
    "Important notes:\n",
    "\n",
    "* This is a statement of __association__, not __causation.__\n",
    "* If an increase in Facebook ad spending was associated with a __decrease__ in sales, $\\beta_1$ would be __negative__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 4:__ Predict the response (sales) on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Test the model on the testing set, and evaluate how well we did.\n",
    "\n",
    "We need an __evaluation metric__ in order to compare our predictions with the actual values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation metrics for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation metrics for classification problems, such as accuracy, are not useful for regression problems. Instead, we need evaluation metrics designed for comparing continuous values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define true and predicted response values\n",
    "true = [100, 50, 30, 20]\n",
    "pred = [90, 50, 50, 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Mean Absolute Error__ (MAE) is the mean of the absolute value of the errors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MAE by hand\n",
    "\n",
    "\n",
    "# calculate MAE using scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Mean Squared Error__ (MSE) is the mean of the squared errors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MSE by hand\n",
    "\n",
    "\n",
    "# calculate MSE using scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Root Mean Squared Error__ (RMSE) is the square root of the mean of the squared errors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE by hand\n",
    "\n",
    "\n",
    "# calculate RMSE using scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing these metrics:\n",
    "\n",
    "* __MAE__ is the easiest to understand, because it's the average error.\n",
    "* __MSE__ is more popular than MAE, because MSE \"punishes\" larger errors.\n",
    "* __RMSE__ is even more popular than MSE, because RMSE is interpretable in the \"y\" units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the RMSE for our sales predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does __Twitter__ \"belong\" in our model? In other words, does it improve the quality of our predictions?\n",
    "\n",
    "Let's __remove__ it from the model and check the RMSE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Python list of feature names\n",
    "\n",
    "\n",
    "# use the list to select a subset of the original DataFrame\n",
    "\n",
    "\n",
    "# select a response from the DataFrame\n",
    "\n",
    "\n",
    "# split into training and testing sets\n",
    "\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "\n",
    "\n",
    "# make predictions on the testing set\n",
    "\n",
    "\n",
    "# compute the RMSE of our predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE __decreased__ when we removed Twitter from the model. (Error is something we want to minimize, so __a lower number for RMSE is better.__) Thus, it is unlikely that this feature is useful for predicting Sales, and should be removed from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "There is a drawback of using the train/test split procedure for model evaluation. The drawback is that we are not using the entire dataset and depending on the observations that are selected for the testing set, the testing accuracy can significantly change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps for K-fold cross-validation\n",
    "1. Split the dataset into K __equal__ partitions (or \"folds\").\n",
    "2. Use fold 1 as the __testing set__ and the union of the other folds as the __training set__.\n",
    "3. Calculate __testing accuracy__.\n",
    "4. Repeat steps 2 and 3 K times, using a __different fold__ as the testing set each time.\n",
    "5. Use the __average testing accuracy__ as the estimate of out-of-sample accuracy.\n",
    "\n",
    "Diagram of __5-fold cross-validation__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cross-validation](images/07_cross_validation_diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration                   Training set observations                   Testing set observations\n",
      "    1     [ 5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]        [0 1 2 3 4]       \n",
      "    2     [ 0  1  2  3  4 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]        [5 6 7 8 9]       \n",
      "    3     [ 0  1  2  3  4  5  6  7  8  9 15 16 17 18 19 20 21 22 23 24]     [10 11 12 13 14]     \n",
      "    4     [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 20 21 22 23 24]     [15 16 17 18 19]     \n",
      "    5     [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]     [20 21 22 23 24]     \n"
     ]
    }
   ],
   "source": [
    "# simulate splitting a dataset of 25 observations into 5 folds\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=False).split(range(25))\n",
    "\n",
    "# print the contents of each training and testing set\n",
    "print('{} {:^61} {}'.format('Iteration', 'Training set observations', 'Testing set observations'))\n",
    "for iteration, dataset in enumerate(kf, start=1):\n",
    "    print('{:^9} {} {:^25}'.format(iteration, dataset[0], str(dataset[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dataset contains __25 observations__ (numbered 0 through 24)\n",
    "* 5-fold cross-validation, thus it runs for __5 iterations__\n",
    "* For each iteration, every observation is either in the training set or the testing set, __but not both__\n",
    "* Every observation is in the testing set __exactly once__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing cross-validation to train/test split\n",
    "\n",
    "Advantages of __cross-validation__:\n",
    "\n",
    "* More accurate estimate of out-of-sample accuracy\n",
    "* More \"efficient\" use of data (every observation is used for both training and testing)\n",
    "\n",
    "Advantages of __train/test split__:\n",
    "\n",
    "* Runs K times faster than K-fold cross-validation\n",
    "* Simpler to examine the detailed results of the testing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cross-validation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold cross-validation with all three features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the sign of MSE scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from MSE to RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold cross-validation with two features (excluding Twitter)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
